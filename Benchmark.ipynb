{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoyyzYxajykvKn5Kum07ol",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KA0335/DeepMirror/blob/main/Benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7NLkYZGtFiv"
      },
      "outputs": [],
      "source": [
        "#installing all dependencies\n",
        "#DeepP\n",
        "!pip install git+https://github.com/bp-kelley/descriptastorus \n",
        "!pip install DeepPurpose\n",
        "!!pip install PyTDC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cloning deeppurpose repo for reference\n",
        "!git clone https://github.com/kexinhuang12345/DeepPurpose.git"
      ],
      "metadata": {
        "id": "FycLxL5bmfJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing all libraries\n",
        "from sklearn import tree\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.metrics as metrics\n",
        "from DeepPurpose import utils, CompoundPred\n",
        "from tdc.single_pred import ADME\n",
        "from os import mkdir\n",
        "from numpy import absolute\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from xgboost import XGBRegressor"
      ],
      "metadata": {
        "id": "_yOGI6JT3wO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MPNN - A supervised GNN\n",
        "def GraphDL(X,y,encoding, data):\n",
        "  drug_encoding = encoding\n",
        "  train, val, test = utils.data_process(X_drug = X, \n",
        "                                        y = y, \n",
        "                                        drug_encoding = drug_encoding,\n",
        "                                        random_seed = 'TDC')# seed name for the dataset\n",
        "  \n",
        "  config = utils.generate_config(drug_encoding = drug_encoding, \n",
        "                          train_epoch = 15, \n",
        "                          LR = 0.002, \n",
        "                          batch_size = 32,\n",
        "                          mpnn_hidden_size = 32,\n",
        "                          mpnn_depth = 2\n",
        "                          )\n",
        "  model = CompoundPred.model_initialize(**config)\n",
        "  # Training\n",
        "  model.train(train, val, test)\n",
        "  model.save_model(data+'/'+encoding+data)"
      ],
      "metadata": {
        "id": "xh05Nd8BrSSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#method to plot XGBoost model\n",
        "def plot_roc(model, X_test, y_test,encoding, data):\n",
        "    # calculate the fpr and tpr for all thresholds of the classification\n",
        "    probabilities = model.predict_proba(np.array(X_test))\n",
        "    predictions = probabilities[:, 1]\n",
        "    fpr, tpr, threshold = metrics.roc_curve(y_test, predictions)\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "    #generating the plots\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.plot([0, 1], [0, 1], 'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.savefig(encoding+\"_\"+data+'.png', bbox_inches='tight')\n",
        "\n",
        "#Method for regression- XGBoost\n",
        "def XGBR(X, y,encoding, data):\n",
        "  model = XGBRegressor(n_estimators=2000, max_depth=30, eta=0.5, subsample=0.7, colsample_bytree=0.2)\n",
        "  # define model evaluation method\n",
        "  cv = RepeatedKFold(n_splits=10, n_repeats=10, random_state=1)\n",
        "  # evaluate model\n",
        "  scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
        "  # force scores to be positive\n",
        "  scores = absolute(scores)\n",
        "  print('Mean MAE: %.3f (%.3f)' % (scores.mean(), scores.std()) )\n",
        "\n",
        "#Method for classification- XGBoost  \n",
        "def XGBC(X, y,encoding, data):\n",
        " \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
        "  model = XGBClassifier()\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  predictions = [round(value) for value in y_pred]\n",
        "  # evaluate predictions\n",
        "  accuracy = accuracy_score(y_test, predictions)\n",
        "  final = confusion_matrix(y_test, predictions)\n",
        "  plot_roc(model, X_test, y_test, encoding, data)\n",
        "  return accuracy\n",
        "\n",
        "#preprocessing the data and making it ready for XGBoost\n",
        "def trainings(X,y,encoding, data, reg):\n",
        "  drug_encoding = encoding\n",
        "  train, val, test = utils.data_process(X_drug = X, \n",
        "                                        y = y, \n",
        "                                        drug_encoding = drug_encoding,\n",
        "                                        random_seed = 'TDC')# seed name for the dataset\n",
        "  \n",
        "  #dropping smile string as we have the encodings now\n",
        "  train = train.drop(['SMILES'], axis=1)\n",
        "  test = test.drop(['SMILES'], axis=1)\n",
        "  val = val.drop(['SMILES'], axis=1)\n",
        "  train = train.append(test)\n",
        "  train = train.append(val)\n",
        "  #separating the labels \n",
        "  y = train.iloc[:,:-1]\n",
        "  z = pd.DataFrame(train[\"drug_encoding\"].to_list(), columns=['1', '2'])\n",
        " \n",
        "  matrix = []\n",
        "  l = len(z)\n",
        "  for i in range(l):\n",
        "      temp = z['1'][i]\n",
        "      # Append an empty sublist inside the list\n",
        "      matrix.append([])\n",
        "      matrix[i].append(temp)\n",
        "  new_mat = np.array(matrix)\n",
        "  reshaped_array=np.reshape(new_mat,(l,50))\n",
        "  if reg == False:\n",
        "  \n",
        "    acc= XGBC(reshaped_array, y, encoding, data)\n",
        "    return acc\n",
        "  else:\n",
        "    acc = XGBR(reshaped_array, y, encoding, data)\n",
        "\n",
        "#training the transformer model\n",
        "def transformer(X,y,encoding, data):\n",
        "  drug_encoding = encoding\n",
        "  train, val, test = utils.data_process(X_drug = X, \n",
        "                                        y = y, \n",
        "                                        drug_encoding = drug_encoding,\n",
        "                                        random_seed = 'TDC')# seed name for the dataset\n",
        "\n",
        "  config = utils.generate_config(drug_encoding = drug_encoding, \n",
        "                          train_epoch = 15, \n",
        "                          LR = 0.001, \n",
        "                          batch_size = 128,\n",
        "                          )\n",
        "  model = CompoundPred.model_initialize(**config)\n",
        "  #Training\n",
        "  model.train(train, val, test)\n",
        "  model.save_model(data+'/'+encoding+data)"
      ],
      "metadata": {
        "id": "AQRb2PsaHu0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#graph neural network\n",
        "metric = {}\n",
        "#dataset for classification\n",
        "            #A          #M              #D\n",
        "dataset = ['HIA_Hou','CYP2C19_Veith','BBB_Martins'] \n",
        "reg = False\n",
        "for data in dataset:\n",
        "  mkdir(data)\n",
        "for data in dataset:\n",
        "  os.chdir('/content/'+data)\n",
        "  X, y = ADME(name = data).get_data(format = 'DeepPurpose')\n",
        "  encoding = 'MPNN'\n",
        "  GraphDL(X,y,encoding, data)\n",
        "  encoding = 'Transformer'\n",
        "  transformer(X,y,encoding, data)\n",
        "  acc = trainings(X,y,encoding, data, reg)\n",
        "  metric[data] = acc\n"
      ],
      "metadata": {
        "id": "G1rkwlCFGuZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDLrgqORotI9",
        "outputId": "5d8a8f81-d889-4e8f-85c7-52d8017d8cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Regression\n",
        "        #E\n",
        "data = 'Half_Life_Obach'\n",
        "mkdir(data)\n",
        "os.chdir('/content/'+data)\n",
        "X, y = ADME(name = data).get_data(format = 'DeepPurpose')\n",
        "encoding = 'MPNN'\n",
        "GraphDL(X,y,encoding, data)\n",
        "encoding = 'Transformer'\n",
        "transformer(X,y,encoding, data)\n",
        "reg = True\n",
        "acc = trainings(X,y,encoding, data, reg)\n",
        "metric[data] = acc"
      ],
      "metadata": {
        "id": "Qj-eBOG-oHoO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}